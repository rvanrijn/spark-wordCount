package nl.ncim.workshop.solutions.core

import org.apache.spark.{SparkContext, SparkConf}
import org.apache.spark.rdd._

/**
 * The Java Spark API documentation: http://spark.apache.org/docs/latest/api/java/index.html
 *
 * Now we use a dataset with 8198 tweets. Here an example of a tweet:
 *
 * {"id":"572692378957430785",
 * "user":"Srkian_nishu :)",
 * "text":"@always_nidhi @YouTube no i dnt understand bt i loved of this mve is rocking",
 * "place":"Orissa",
 * "country":"India"}
 *
 * We want to make some computations on the hashtags. It is very similar to the exercise 2
 * - Find all the hashtags mentioned on a tweet
 * - Count how many times each hashtag is mentioned
 * - Find the 10 most popular Hashtag by descending order
 */
object Sol3HashTagMining {

  val pathToFile = "data/reduced-tweets.json"

  /**
   * Load the data from the json file and return an RDD of Tweet
   */
  def loadData(): RDD[Tweet] = {
    // create spark configuration and spark context
    val conf = new SparkConf()
      .setAppName("Hashtag mining")
      .setMaster("local[*]")
      .set("spark.driver.allowMultipleContexts", "true")

    val sc = new SparkContext(conf)

    // Load the data and parse it into a Tweet.
    // Look at the Tweet Object in the TweetUtils class.
    sc.textFile(pathToFile)
      .mapPartitions(TweetUtils.parseFromJson(_))
  }

  /**
   * Find all the hashtags mentioned on tweets
   */
  def hashtagMentionedOnTweet() = {
    val tweets = loadData

    tweets.flatMap(_.text.split(" ").filter(_.startsWith("#")).filter(_.length > 1))
  }


  /**
   * Count how many times each hashtag is mentioned
   */
  def countMentions() = {
    val tags = hashtagMentionedOnTweet

    tags.map((_, 1)).reduceByKey(_ + _)
  }

  /**
   * Find the 10 most popular Hashtags by descending order
   */
  def top10HashTags() = {
    val count = countMentions

    count.sortBy(_._2, false, 1).take(10)

  }

}
